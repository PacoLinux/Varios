\documentstyle{amsart}
\title{Set type implementation conformant with Pascal Standard}
\begin{document}

Standard requires that sets are compatible for operations if the types
that are their elements are themselves members of a common type.
Thus a SET OF A is compatible with a SET OF B if there exists a
type C such that all elements of A and all elements of B are members
of C.

A set denotation of the form \[a,b, d..e, f\] is in terms of the standard
an unpacked set. A bitmap implementation of a set is termed a packed
set. A set type can be declared to be a packed set.

An unpacked set is already available to us in the generic set representation
as trees. These should probably be amended to allow ranges to be explicitly included
in the implementation.

\section{Packed set implementation}
A packed set will be represented as an underlying array type. The type
will be an array of bytes with explicit bounds.
Thus the type
\begin{verbatim}
S:SET of A..B;

\end{verbatim}
Will be represented as the array type
\begin{verbatim}
V:ARRAY [x..y] of byte;
\end{verbatim}
where x= ord(A) div 8, y= ord(B) div 8.

Member C of S will be represented by bit (ord(C) mod 8) of V\[ord(c) div 8\].

Assignments of the form
$S1:= S2 \Omega S3$, where $S1, S2, S3$ are packed sets whose base types share a common supertype,
and $\Omega$ is some non-relational set operator,
will be implemented using the standard Vector Pascal array overloading by
translating them into the equivalent array statement

$V1:= V2 \omega V3$ where $V1,V2,V3$ are the corresponding implementation arrays
of bytes and $\omega$ is the corresponding bit wise binary operator.
This implies that range checking will be performed on the arrays and that
run time bounds exceptions could arise. This has potential implications for
the handling of array ranges in normal array expressions.

Consider the following
\begin{verbatim}
s1 : set of 0..63;
s2 : set of 24..39;
s3 : set of 32..47;
\end{verbatim}
the corresponding vectors will be
\begin{verbatim}
v1: array [0..7] of byte;
v2: array [3..4] of byte;
v3: array [4..5] of byte;
\end{verbatim}then
the following is a valid Standard Pascal sequence of statements:
\begin{verbatim}
 s2:=[24,32]; s3:=[32,33,40]; s1:=s2+s3;
\end{verbatim}
translating this to the equivalent vector code naively we get:
\begin{verbatim}
const t2:array[3..4] of byte=(1,1); 
      t3:array[4..5] of byte=(3,1);
...
	v2:=t2; 
	v3:=t3; 
	v1:=v2 or v3;
\end{verbatim}
The third assignment would under current definitions of vector overloading
expand out to:
\begin{verbatim}
for i:= 0 to 7 do v1[i]:= v2[i] or v3[i]
\end{verbatim}
which would of course lead to an array bounds fault since 0 is outside the
bounds of the arrays v2 and v3.

A safe translation would be
\begin{verbatim}

var temp1,temp2:byte;
    i:0..7;
...
for i:= 0 to 7 do begin
	if (i >= lwb(v2)) and (i<=upb(v2) then 
          temp1:= v2[i]
	else
	  temp1:=0;
 	if (i >= lwb(v3)) and (i<=upb(v3) then 
          temp2:= v3[i]
	else
	  temp2:=0;

	v1[i]:= temp1 or temp2
end
\end{verbatim}

This is relatively inefficient and it would clearly be desireable to
remove the range tests in those circumstances where they are unnecessary,
for instance when all 3 arrays had the same bounds.

This should be possible if the type of i is propagated down to the 
dead code removal layer.

\section*{For in statements}
Extended
\end{document}
